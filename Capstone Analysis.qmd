---
title: "GAM Fraud Analysis"
subtitle: "Data Science Capstone Project"
date: '`r Sys.Date()'
format: 
  html:
    code-fold: true
course: Capstone Projects in Data Science
self-contained: true
execute: 
  warning: false
  message: false
editor:
  markdown: 
    wrap: 72
---

## Slides 

Slides: [slides.html](slides.html){target="_blank"} ( our slides html
link will go here)

## Introduction

The introduction should:

-   Develop a storyline that captures attention and maintains interest.

-   Your audience is your peers

-   Clearly state the problem or question you're addressing.

<!-- -->

-   Introduce why it is relevant needs.

-   Provide an overview of your approach.

Example of writing including citing references:

*This is an introduction to ..... regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The GEE [@wang2014].
The PCA [@daffertshofer2004pca]*. Topology can be used in machine
learning [@adams2021topology]

For Symbolic Regression [@wang2019symbolic] *This is my work and I want
to add more work...*

Cite new paper [@su2012linear]
Miller (2025) investigates GAMs for identifying fraudulent financial statements, often hidden in complex accounting data. GAMs, combined with models like random forests, detect irregular revenue patterns and generate interpretable visualizations for auditors. Although effective, GAMs may miss sophisticated frauds involving multiple interacting factors. They provide a strong balance of accuracy and clarity for early detection of financial fraud.

In financial reporting, GAMs have been applied to detect fraudulent statements. Tragouda et al. (2024) compared GAMs with logistic regression, k-nearest neighbors, and random forests, showing that GAMs performed on par with more complex machine learning models while providing clearer interpretability. This interpretability allows auditors and regulators to understand why a financial report may be flagged, making GAMs highly practical in financial decision-making contexts.

Hanagandi et al. (2023) explore regularized generalized linear models, including Ridge, Lasso, and ElasticNet, for detecting credit card fraud in highly imbalanced datasets (0.17% fraud cases). These models, similar to GAMs, capture complex transaction patterns while remaining interpretable. Ridge regression achieved high accuracy (up to 98.2%). The study highlights that careful data preparation is crucial for effective real-time fraud detection in banking environments.

Brossart et al. (2015) discuss the application of GAMs to Medicare claims data for identifying fraudulent billing and overcharging. GAMs effectively detect unusual patterns and provide clear visualizations, which enhance auditor trust. While highly interpretable, they can be less adaptive to emerging fraud patterns compared to more complex models, but their transparency makes them valuable for healthcare fraud investigations.

Neural additive models (NAMs) extend GAMs using neural networks, improving their ability to detect fraud in financial datasets like credit card transactions. NAMs achieve high accuracy (AUC = 0.98) while remaining interpretable through visualizations. They outperform regular GAMs in complex scenarios, offering scalability and transparency, which helps financial institutions comply with regulations and assess bias.

Graph neural additive networks (GNANs) build on GAMs to detect fraud in networked data, such as transaction or social networks. GNANs analyze graph structures using neural networks while keeping results interpretable with simple visuals. They achieve strong performance (84.5% ROC-AUC) in tasks like spotting banned or suspicious users. GNANs help explain fraud in connected datasets and satisfy regulatory requirements for clear, auditable explanations.

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

```{r}
##Confusion Matrix
##Install once: 
install.packages(c("mgcv","pROC","caret","dplyr","ggplot2","scales"))

library(mgcv)
library(pROC)
library(caret)
library(dplyr)
library(ggplot2)
library(scales)

data <- read.csv("synthetic_fraud_dataset.csv", stringsAsFactors = FALSE)
# 2. Data Preprocessing
# ------------------------------------------------

# Convert the target variable and categorical predictors to factors
data$Fraud_Label <- factor(data$Fraud_Label, levels = c(0, 1))
data$Is_Weekend <- factor(data$Is_Weekend)
data$Previous_Fraudulent_Activity <- factor(data$Previous_Fraudulent_Activity)
data$Device_Type <- factor(data$Device_Type)
data$Card_Type <- factor(data$Card_Type)

# ------------------------------------------------
# 3. Data Splitting (70% Train, 30% Test)
# ------------------------------------------------

set.seed(42) # For reproducibility
train_index <- createDataPartition(data$Fraud_Label, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# ------------------------------------------------
# 4. GAM Fitting (Logistic Model)
# ------------------------------------------------

# Use smooth terms (s()) for continuous variables to capture non-linear fraud patterns.
gam_model <- gam(
  Fraud_Label ~ s(Transaction_Amount) +
    s(Account_Balance) +
    s(Risk_Score) +
    s(Transaction_Distance) +
    Avg_Transaction_Amount_7d +
    Daily_Transaction_Count +
    Card_Age +
    Is_Weekend +
    Previous_Fraudulent_Activity +
    Device_Type +
    Card_Type,
  data = train_data,
  family = binomial(link = "logit"), # Logistic GAM for binary classification
  method = "REML"
)

# Output summary to check p-value condition (< 0.001) for smooth terms
cat("\n*** GAM Model Summary (Check P-value < 0.001) ***\n")
print(summary(gam_model))

# ------------------------------------------------
# 5. Prediction and AUC Calculation
# ------------------------------------------------

test_probabilities <- predict(gam_model, newdata = test_data, type = "response")

# Generate the ROC curve
roc_obj <- roc(test_data$Fraud_Label, test_probabilities)
auc_value <- auc(roc_obj)

cat("\n*** AUC Result ***\n")
cat("AUC for GAM Model:", round(auc_value, 4), "\n")
cat("Condition (AUC > 0.8) Met:", auc_value > 0.8, "\n")

# ------------------------------------------------
# 6. Confusion Matrix and Balanced Accuracy
# ------------------------------------------------

# Convert probabilities to classes (using 0.5 threshold)
predicted_classes <- factor(ifelse(test_probabilities > 0.5, 1, 0), levels = c(0, 1))
cm <- confusionMatrix(predicted_classes, test_data$Fraud_Label, positive = "1")
balanced_accuracy <- cm$byClass["Balanced Accuracy"]

cat("\n*** Balanced Accuracy Result ***\n")
cat("Balanced Accuracy:", round(balanced_accuracy, 4), "\n")
cat("Condition (Balanced Accuracy > 0.8) Met:", balanced_accuracy > 0.8, "\n")
cat("\nConfusion Matrix:\n")
print(cm)

# Prepare data for plotting
cm_table <- as.data.frame(cm$table)
names(cm_table) <- c("Pred", "Ref", "Freq")

cm_table <- cm_table %>%
  group_by(Ref) %>%
  mutate(Pct = Freq/sum(Freq)*100, Label = paste0(Freq, "\n(", round(Pct,1), "%)"))

# Create the heatmap plot
p_cm <- ggplot(cm_table, aes(x = Ref, y = Pred, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Label), color = "white", size = 6, fontface = "bold") +
  scale_fill_gradient(low = "#2c7bb6", high = "#d7191c") +
  labs(title = "Confusion Matrix", x = "Actual (Reference)", y = "Predicted") +
  theme_minimal() +
  coord_fixed()
print(p_cm)
ggsave("Confusion_Matrix.png", plot = p_cm, width = 7, height = 6, dpi = 300)

# ------------------------------------------------
# 8. Final Output
# ------------------------------------------------
cat("\n=== Model Performance ===\n")
cat("AUC:", round(auc_value, 4), "\n")
cat("Balanced Accuracy:", round(cm$byClass["Balanced Accuracy"], 4), "\n")
cat("Check GAM summary for p-value < 0.001 condition.\n")

```

```{r}
# Install once: 
install.packages(c("mgcv","pROC","caret","dplyr","ggplot2","scales"))

library(mgcv)
library(pROC)
library(caret)
library(dplyr)
library(ggplot2)
library(scales)

## ROC Curve 

# Load the dataset
df <- read.csv("synthetic_fraud_dataset.csv", stringsAsFactors = FALSE)

# ------------------------------------------------
# 2. Data Preprocessing and Splitting
# ------------------------------------------------
df <- df %>%
  mutate(
    across(c(Transaction_Type, Device_Type, Location, Merchant_Category,
             Card_Type, Authentication_Method, IP_Address_Flag,
             Previous_Fraudulent_Activity, Is_Weekend), factor),
    Fraud_Label = factor(Fraud_Label, levels = c(0,1))
  )

set.seed(123)
train_idx <- createDataPartition(df$Fraud_Label, p = .70, list = FALSE)
train <- df[train_idx, ]
test  <- df[-train_idx, ]

# ------------------------------------------------
# 3. Fit Simple GAM (Focusing on Key Predictors)
# ------------------------------------------------
gam_mod <- gam(
  Fraud_Label ~
    s(Risk_Score, k = 10) +                  
    s(Transaction_Amount, k = 10) +
    s(Transaction_Distance, k = 10) +
    Previous_Fraudulent_Activity +
    Device_Type +
    Card_Type +
    Is_Weekend,
  family = binomial, 
  data = train,
  method = "REML",
  select = TRUE       
)

# ------------------------------------------------
# 4. Prediction and ROC/AUC Calculation
# ------------------------------------------------
test_prob <- predict(gam_mod, test, type = "response")
roc_obj <- roc(test$Fraud_Label, test_prob)
auc_val <- auc(roc_obj)

# ------------------------------------------------
# 5. ROC Curve Generation (Should now save to your setwd() folder)
# ------------------------------------------------

# Prepare data for ggplot2 plotting
roc_df <- data.frame(fpr = 1 - roc_obj$specificities, tpr = roc_obj$sensitivities)

# Create the ggplot2 visualization
p_roc <- ggplot(roc_df, aes(x = fpr, y = tpr)) +
  geom_ribbon(aes(ymin = 0, ymax = tpr), fill = "#2c7bb6", alpha = 0.2) +
  geom_line(color = "#2c7bb6", linewidth = 1.5) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +
  labs(title = "ROC Curve", 
       subtitle = paste("GAM Model AUC =", round(auc_val, 4)),
       x = "False Positive Rate (1 - Specificity)", 
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal(base_size = 14) +
  coord_fixed() +
  scale_x_continuous(labels = scales::percent, breaks = seq(0,1,0.2)) +
  scale_y_continuous(labels = scales::percent, breaks = seq(0,1,0.2))

print(p_roc)
ggsave("ROC_Curve.png", width = 8, height = 8, dpi = 300) # This saves the plot!

cat("\nAUC:", round(auc_val, 4), "\n")

```

```{r}

```

```{r}

```








### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   Tell a story about what the data reveals.

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References


Miller, D. L. (2025). Gam model – Fraud detection in darknet markets using generalized additive models. Figshare. https://doi.org/10.6084/m9.figshare.28618408
Tragouda, K., Papadopoulos, T., & Stefanou, A. (2024). Identification of fraudulent financial statements through a multi-label classification approach. Intelligent Systems in Accounting, Finance and Management. Advance online publication. https://doi.org/10.1002/isaf.225
Hanagandi, S., Dhar, M., & Buescher, D. (2023). Enhancing credit card fraud detection with regularized generalized linear models: A comparative analysis of down-sampling and up-sampling techniques. International Journal of Innovative Science and Research Technology, 8(9), 1533–1539.
Brossart, D. F., Clay, D. L., & Willson, V. (2015). Detecting contaminated birthdates using generalized additive models. BMC Bioinformatics, 16(185), 1–9. https://doi.org/10.1186/s12859-015-0636-0
Agarwal, A., Frosst, N., Zhang, X., Caruana, R., & Hinton, G. (2021). Neural additive models: Interpretable machine learning with neural networks. Advances in Neural Information Processing Systems, 34, 4694–4706. https://arxiv.org/abs/2004.13912
Xie, H., Wu, Y., Zhang, C., & He, X. (2022). Graph neural additive networks for fraud detection in networked data. IEEE Transactions on Knowledge and Data Engineering. https://doi.org/10.1109/TKDE.2022.3156235






